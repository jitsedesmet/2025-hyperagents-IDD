## Introduction
{:#introduction}

<span class="comment" data-author="RV">TODO: At some point in intro (preferably soon) make it concrete by going to HTTP and HTTP API resources. It's too abstract. You can explain the thing in HTTP without losing generality. But the current generality loses concreteness.</span>

[Decentralized data ecosystems](cite:cites solid, idsa, gaia-x) are reshaping how data is stored, accessed, and governed.
Rather than centralizing data around <em>data consumers</em>, these ecosystems center around <em>data producers</em>,
empowering individuals and organizations to maintain <del class="comment" data-author="RV">ownership</del> <ins class="comment" data-author="RV">agency</ins> and control while facilitating collaboration.
<span class="comment" data-author="RV"><q>data ownership</q> does not exist (legally and otherwise); let's avoid writing it</span>
This shift brings clear benefits:

1. it facilitates <em>collaboration across organizational boundaries</em> despite differing data models and objectives,
2. it <em>reduces redundant data replication</em> through fine-grained access policies, and
3. it enables diverse applications to <em>reuse shared data sources</em>.

These properties are particularly beneficial in the re-emerging age of agentic AI wherein
autonomous systems capable of acting on behalf of individuals.
<span class="comment" data-author="RV">why? consider removing sentence</span>

<span class="comment" data-author="RV">Introduce the switch to changing the world more explicitly here. Needs to be something like <q>well it's one thing for read, where it's about completeness and efficiency, but with write, where agents can cause state changes to the world, there are stronger concerns</q></span>
However, agentic systems –
whether powered by stochastic language models or deterministic query engines –
require a precise understanding of both the semantics and the consequences of the actions they perform.
When these systems interact with decentralized data sources, they need to know:

1. What does it <em>mean</em> to write data here?
2. What <em>state changes</em> will this action trigger?
3. How <del class="comment" data-author="RV">are resources and their representations <em>manipulated</em></del> <ins class="comment" data-author="RV">does the interface reflect those changes</ins> after completion (or in case of failure)?

<span class="comment" data-author="RV">Point 3 seemed to require an understanding of REST most readers won't have, and also comes out of the blue here (so even those who know, might not realize it's about REST here). See remark below about establishing HTTP as a context.</span>

In practice, today's interfaces rarely answer these questions fully.
Descriptions are often partial, human-readable, and inconsistently maintained.
As a result,
autonomous agents operate with brittle assumptions and incomplete models of the systems they interact with.

<!-- I think a lot of this can be removed since the focus is no longer on 'just' decentralized data ecosystems -->
<span class="comment" data-author="RV">Can we be more explicit here? Set the context to symmetric HTTP-based CRUD operations on resources. That makes it less abstract and more concrete. It's what I had in mind when reading this.</span>
One key insight from previous research is that simple interfaces (e.g. [LDP](cite:cites spec:ldp)) –
where the manipulation of one resource does not have effects on the manipulation of another<del class="comment" data-author="RV">,
and where data manipulations outside of CRUD are not supported</del> –
<span class="comment" data-author="RV">That bit about CRUD is not clear. Everything is CRUD.</span>
[have difficulty supporting complex access policies required in these ecosystems](cite:cites whatsinapod).
Asymmetric interfaces,
in which the manipulation of one resource can have consequences on the manipulation of another,
and data manipulation methods can be used to enact consistency boundaries,
<span class="comment" data-author="RV">I don't get that last bit</span>
are a more promising fit.
Unfortunately, they introduce a new challenge for autonomous agents, as write semantics become opaque.
A write operation to one endpoint can have various consequences on different resources.
This creates a semantic gap that prevents agents from reliably reasoning over their own actions.
At the same time, the same resources can be exposed in different ways, such as through different fragmentations or interaction methods,
each having their own benefits and drawbacks [](cite:cites tpf, hartig2017formal).
<div class="comment" data-author="RV" markdown=1>I get what you're trying to say because I have the extra context, but most people won't. If you want to make this kind of argument, I suggest to have a subsection READ where you move this bit, and a subsection WRITE. I think it will be easier to make the argument from the two perspectives: first, explain the options for READ and why it is easy (it's an efficiency/optimization problem, finding the most optimal way of accessing the data). Second, explain how WRITE is a different problem space, not efficiency but feasibility; without simple CRUD, write operations can have ripple effects on other resources. READ never has effects, let alone ripple effects.
Suggested structure:

### _Read_ operations

#### Simple CRUD, each data point in one place
- no probs

#### Complex CRUD, each data point in multiple fragments
- caused by efficiency [tpd] and policies [whatsinapod]
- no probs, just suboptimal if you choose wrong


### _Write_ operations
#### Simple CRUD
- you change the world but at least it's predictable

#### Complex CRUD
- holy fuck what have I done

</div>

Moreover, in dynamic environments these [choices of fragmentation and interaction methods can change](cite:cites dynamic-interfaces),
mirroring the elasticity of cloud infrastructure.
<span class="comment" data-author="RV">good and important point: we can't hardcode because it changes all the time</span>

To manage these complexities,
<span class="comment" data-author="RV">be more specific</span>
we propose a framework that algebraically describes (e.g. relational or SPARQL algebra) the relationship between write operations,
resource manipulations, and the exposed resource representations using shape graphs.

<figure id="interface-viz">
<img src="images/interface-example-viz.svg" alt="Visual representation of the interface" style="object-fit: contain; width: 50%"/>
<figcaption markdown="block">
Overview of the interface description of the example <em>pet shop</em> interface.
Resources are modeled on a white background identified with the IRI above them.
Ovals are exposed resources and the arrows depict explicitly modeled dependencies between resources.
This description allows agents to manipulate intermediate resources.
</figcaption>
</figure>

### Motivating use case

Throughout this paper we will use [](#interface-viz) as an example use case to motivate our approach.
Our use case is an API around a database containing owners and their pets.
We include five endpoints families:
1. [**\<get-owners\>**](#5.get-owners): retrieves a list of URIs representing all registered owners
2. [**\<get-owner\>**](#6.get-owner): fetches an individual owner along with their associated pets
3. [**\<post-owner\>**](#1.post-owner): registers a new owner in the system
4. [**\<patch-owner\>**](#2.patch-owner): updates an existing owner
5. [**\<change-owner\>**](#3.change-owner): transfers a pet from one owner to another.
Important to note is that our system _explicitly_ models the `<database>` information resource, meaning other systems can now reference the resource 
'_all known owners and their pets registered in service X_', and deduce what endpoints manipulate it.

This paper presents <del class="comment" data-author="RV">a vision for a future in which</del> interfaces <ins class="comment" data-author="RV">that</ins> formally describe their underlying resources and how to manipulate them,
creating rich, composable, and formal interface semantics.
Our goal is to stimulate discussion on how such descriptions can support autonomous operation,
improve agent reliability, and pave the way for more interoperable and adaptive knowledge infrastructures.
While the proposed direction remains conceptual,
we offer initial ideas and mappings that illustrate how this approach could be realized in practice.

In the [next section](#related-work) we review related work, discussing various existing ways to describe data interfaces.
In [](#vision) we detail our vision, and we conclude our paper in [](#conclusion).
[](#annex) contains the complete description of our example in [](#interface-viz).
