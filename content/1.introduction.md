## Introduction
{:#introduction}

Many years of exposing semantic data has learned the semantic web community valuable lessons.
One of those lessons has been that [the perfect interface does not exist](cites:cites tpf, hartig2017formal).
In fact, the perfect interface depends on the current query type and load, which is use case dependent.

As such, a dataset that is used in multiple use cases, with possibly vastly different requirements,
could benefit from being exposed through heterogeneous read/write interfaces, effectively creating a [polyglot system](cite:cites khine2019review).
This case of a dataset being required in multiple use cases currently exists in the world of personal datastore's,
be it for agentic AI systems or decentralized data ecosystems in general.
A single organisations personal dataset is consumed and updated in the context of various use-cases.

When multiple interfaces expose the same data however,
it is essential that the interfaces describe their relationship with each-other by individually describing their relation to the data.
Using such a description, multiple interfaces can expose the same, partially overlapping data, and consumers of these interfaces can understand the relationship between interfaces and data.

Currently, effectively querying data and effectively exposing data is seen as separate problems since
each party, the data consumer and data provider want to optimize with their own constraints in mind.
This sometimes causes a language mismatch since both parties actually
just want effective communication stimulating the flow and effective use of data.

Traditionally, data providers describe their interface by providing a human-readable description of what
operations the server supports, and what clients can expect when performing these operations, be it a change of the dataset, or receiving some data.
In the context of web interfaces, these operations consist of a method called on some URI using a body and metadata headers.
This human-readable description however fails to label the effective dataset being used -
it is just assumed that a single description is used for a single dataset -
but this assumption is false in the context of polyglot datasets, since multiple interfaces can expose the same data.

Another approach to describe data interfaces has been to define the semantics of the returned data.
This does TODO.

What to the best of the authors knowledge has not been tried is to express the relationship of an interface through algebraic definitions
such as SQL algebra or SPARQL algebra which can be optimized and understood by query engines.
When your data model exists in a space $ \doubleD $ and you have an algebra that works from $ doubleO -> doubleO $,
you can express data as it evolves throughout the system.

Additionally, there is the need for machine understandable descriptions when you are dealing
with ever-changing interfaces or when sources are only known at runtime.
Ever-changing interfaces mean that the interface itself changes to balance against the current query type and load.
An ever-changing interface is similar to the dynamic scalability found cloud infrastructure.
Depending on the current traffic, the interface may restructure itself to match the load of that time.

When the datasets consumed are not known until runtime,
there is also a need for the machine to decide at runtime what it can expect from the interfaces discovered at runtime. 

